{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7988e8c2",
   "metadata": {},
   "source": [
    "# State:  \n",
    "\n",
    "{\n",
    "input_h : [x,x,x,x,x]\n",
    "server_load :[y,y,y] depends on input_h\n",
    "}\n",
    "\n",
    "# State+1:\n",
    "\n",
    "# Goal: Train a policy that works for a wide range of wireless gain channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e069ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\donvi\\.conda\\envs\\DROO\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: calling function (from tensorflow.python.eager.def_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Box,Dict,Discrete\n",
    "import numpy as np\n",
    "import random\n",
    "import ray\n",
    "from ray.rllib.algorithms import ppo\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Must define self.observation_space and self.action_space here\n",
    "        \"\"\"\n",
    "        # Define action space: bounds, space type, shape\n",
    "\n",
    "        # Bound: Action_space is based on the number of servers +1. For this case, we set it to 3. (3 servers)\n",
    "        \n",
    "        self.max_choices = 4\n",
    "        self.count = 0\n",
    "        #Space type: Better to use Box than Discrete, since Discrete will lead to too many output nodes in NN\n",
    "        #Shape: rllib cannot handle scalar actions, so we turn it into a numpy array with shape (1,) \n",
    "        #self.action_space = Box(low = np.array([0]), high = np.array([self.max_choices]))\n",
    "        self.action_space = Discrete(self.max_choices)\n",
    "        # Bound: Observation_space\n",
    "        # input_h is the channel gain between the access point and device x (), assume we have 5 devices\n",
    "        # decisions is the choice made by the agent to decide the resource allocation of each device\n",
    "        #server_load = load of each server at the moment\n",
    "        #obs_low = np.zeros((self.obs_dim,))\n",
    "        \n",
    "        self.numServers = 3 # number of servers or base stations\n",
    "        \n",
    "        self.observation_space = Dict(\n",
    "        {\n",
    "         'input_h': Box(low = np.full(5, -np.inf), high = np.full(5, np.inf), shape = (5,), dtype = np.float),\n",
    "         #'decisions': spaces.Box(low =np.full(5, 0), high = np.full(5,4), shape = (5,), dtype = np.intc)\n",
    "         'server_load': Box(low = np.zeros(self.numServers), high = np.full(3, np.inf), shape = (3,), dtype = np.float)\n",
    "        })        \n",
    "        \n",
    "        self.current_obs = None\n",
    "        self.log = ''\n",
    "\n",
    "    \n",
    "    def reset(self, next_input):\n",
    "        \"\"\" \n",
    "        Returns: observation of the initial state\n",
    "        Reset environment to initial state so that a new episode independent of previous ones can start\n",
    "        We want to reset input_h to next set of input_h, rest to 0.\n",
    "        \"\"\"\n",
    "        input_h = next_input\n",
    "        server_load = np.zeros(self.numServers)\n",
    "        #decisions = np.full(5,0)\n",
    "        self.current_obs = {\n",
    "            'input_h': input_h,\n",
    "            'server_load' : server_load\n",
    "            #'decisions': decisions\n",
    "        }\n",
    "        self.count = 0\n",
    "        \n",
    "        return self.current_obs\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns the next observation, reward, done and optinally additional info\n",
    "        \"\"\"\n",
    "        #Action looks like np.array. convert to float for easier calculation.\n",
    "        print(self.count)\n",
    "        choice = random.choice(action)\n",
    "        print(f'Chosen choice: {choice}')\n",
    "        self.log += f'Chosen action: {choice}\\n'\n",
    "        \n",
    "        #Compute next observation\n",
    "        self.current_obs['server_load'][choice] += 1\n",
    "        next_obs = self.current_obs\n",
    "        \n",
    "        #Compute reward\n",
    "        if self.count < 4:\n",
    "            reward = 0\n",
    "        if self.count ==4:\n",
    "            reward = self.current_obs['server_load'][0]*self.current_obs['input_h'][self.count] + self.current_obs['server_load'][1]*self.current_obs['input_h'][self.count] + self.current_obs['server_load'][2]* self.current_obs['input_h'][self.count]\n",
    "            print(\"reward\",reward)\n",
    "        done = False\n",
    "        if self.count == 4:\n",
    "            done = True\n",
    "        self.count+=1\n",
    "        self.current_obs = next_obs\n",
    "        return self.current_obs, reward, done, {}\n",
    "    def render(self):\n",
    "        \"\"\"\n",
    "        Show current environment state\n",
    "        Must be implemented, if not important, can have an empty implementation\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def close(self): # optional\n",
    "        \"\"\"\n",
    "        Used to clean up all resources. Optional\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def seed(self): # optional\n",
    "        \"\"\"\n",
    "        Used to set seeds for environment's RNG for obtaining deterministic behavior. Optional\n",
    "        \"\"\"\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c91393cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\donvi\\.conda\\envs\\DROO\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\donvi\\.conda\\envs\\DROO\\lib\\site-packages\\ipykernel_launcher.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39290819 0.38042677 0.19196273 0.82057973 0.33301518]\n",
      "test\n",
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\TempFiles\\ipykernel_12140\\1972543536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#assert np.all(obs <= env.observation_space.high), f\"Observation {obs} does not respect observation space upper bound\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\TempFiles\\ipykernel_12140\\2769215494.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m#Action looks like np.array. convert to float for easier calculation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mchoice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Chosen choice: {choice}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf'Chosen action: {choice}\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\DROO\\lib\\random.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;34m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "env = CustomEnv()\n",
    "\n",
    "for _ in range(10):    \n",
    "    arr = np.random.rand(5)\n",
    "    print(arr)\n",
    "    obs = env.reset(arr)\n",
    "    while True:\n",
    "        print(\"test\")\n",
    "        action = env.action_space.sample()\n",
    "        \n",
    "        obs,r,done, _ = env.step(action)\n",
    "        #assert np.all(obs <= env.observation_space.high), f\"Observation {obs} does not respect observation space upper bound\"\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd2a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c86bd2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a32271a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e0c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DROO]",
   "language": "python",
   "name": "conda-env-.conda-DROO-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
